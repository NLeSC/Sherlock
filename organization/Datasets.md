
Open email datasets
-------------------

Enron email dataset contains around 600,000 emails generated by 158 employees (mostly upper management) of the Enron Corporation:

* https://en.wikipedia.org/wiki/Enron_Corpus 
* http://www.edrm.net/resources/data-sets/edrm-enron-email-data-set

The Apache Foundation Mail Archives contains a complete historical archive of messages posted to the public mailing lists of the Apache Software Foundation projects:

* http://mail-archives.apache.org/mod_mbox/


Document datasets
-----------------

The arXiv.org site contains 1M open access papers on various topics in in Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance and Statistics:

* http://arxiv.org/help/bulk_data


Social media(-ish)
------------------

The TwiNL project collects Dutch language tweets since december 2010. About 40% of all Dutch tweets are stored. 

* http://145.100.57.140/cgi-bin/twitter 
* http://twiqs.nl http://twiqs.nl

The WestburyLAB usenet corpus is a collection of public USENET postings collected between Oct 2005 and Jan 2011, and covers 47,860 English language, non-binary-file news groups:

* http://www.psych.ualberta.ca/~westburylab/downloads/usenetcorpus.download.html

1 terabyte corpus of Reddit comments from October of 2007 until May of 2015.

* [https://archive.org/details/2015_reddit_comments_corpus](https://archive.org/details/2015_reddit_comments_corpus)

Web pages
---------

ClueWeb-09 and 12 datasets are part of TREC and contain around 1 billion web pages that can be used to support research on information retrieval and related human language technologies:

* http://www.lemurproject.org/clueweb09/ 
* http://www.lemurproject.org/clueweb12.php/

Wikipedia provides dumps of their pages:

* https://en.wikipedia.org/wiki/Wikipedia:Database_download 

Reviews
-------

Amazon product dataset contains 143.7 million product reviews spanning May 1996 - July 2014 and includes product metadata and links: 

* http://jmcauley.ucsd.edu/data/amazon/


Handwriting, OCR, etc.
----------------------

The MNIST database of handwritten digits:

* http://yann.lecun.com/exdb/mnist/ 


Image datasets
--------------

Image-net is an image database organized according to the [WordNet](http://wordnet.princeton.edu/) hierarchy (currently only the nouns), in which each node of the hierarchy is depicted by hundreds and thousands of images. It is used in a yearly challenge. The URLs to the images and various meta information is available at: 

* http://www.image-net.org/ http://www.image-net.org/

Yahoo 100M dataset contains a list of URLs (and metadata) to photos and videos on Flickr licensed under one of the Creative Commons copyright licenses:

* [http://webscope.sandbox.yahoo.com/catalog.php?datatype=i&did=67](http://webscope.sandbox.yahoo.com/catalog.php?datatype=i&did=67)

The PEC dataset contains is used for 'event recognition'. It contains 61364 images (11GB) divided into 807 collections, where each collection is a series of images of the same event. For example, they have 60 collections of 
'birthday' images, where each collection contains about 55 photos of the same birthday party, in the same place, with the same people.

* http://www.vision.ee.ethz.ch/datasets_extra/pec/

The Dresden dataset is used for camera identification. It contains more than 4,000 images of various indoor and outdoor scenes have been acquired under controlled and thus widely comparable conditions from altogether 73 digital 
cameras. The cameras were drawn from only 25 different models to ensure that device-specific and model-specific characteristics can be disentangled and studied separately.

* http://forensics.inf.tu-dresden.de/publications/Gloe10_DDImgDB.pdf
* http://forensics.inf.tu-dresden.de/ddimgdb


Forensic Data sets.
-------------------

A large number of forensic data sets can be found online. The most interesting link is:

* http://forensicswiki.org/wiki/Forensic_corpora

One interesting catagpry is 'Honeynet Project Scans of the Month', which provides monthly chalenges. Also see the Sleuth Kit's Wiki lists Brian Carrier's responses to those challenges:

* http://wiki.sleuthkit.org/index.php?title=Case_Studies

Computer Forensic Reference Data Sets project at

* http://www.cfreds.nist.gov/
* http://www.cfreds.nist.gov/Hacking_Case.html 

hosts a few sample cases that may be useful for examiners to practice with.

The Digital Forensic Research Workshop's Rodeos and Challenges released their data and scenario writeups. The following had disk images as parts of their scenario:

* http://www.cfreds.nist.gov/dfrws/Rhino_Hunt.html
* http://dfrws.org/2008/rodeo.shtml
* http://dfrws.org/2009/rodeo.shtml
* http://dfrws.org/2009/challenge/index.shtml 2009
* http://dfrws.org/2011/challenge/index.shtml 2011


British National Corpus
-----------------------

A 100 million word collection of written and spoken english from a variety of sources:

* http://www.natcorp.ox.ac.uk/

Contemporary Dutch Corpus (Corpus Hedendaags Nederlands)
--------------------------------------------------------

Over 800,000 Dutch texts from newspapers, magazines, news broadcasts, and legal material from 1814 until 2013. You need to make a Clarin account to access the corpus. Also, because of license issues, we cannot download the corpus. We are, however, welcome to bring our tools to the INL and try it there.

* [https://portal.clarin.inl.nl/search/page/search](https://portal.clarin.inl.nl/search/page/search)

Augmented Multi-Party Interaction Corpus
----------------------------------------

This corpus contains a 100 hours of meeting recordings.

* http://corpus.amiproject.org

Other Corpora
-------------

* Under an NSF grant, Kam Woods and [Simson Garfinkel](http://forensicswiki.org/wiki/Simson_Garfinkel) created a website for digital corpora [http://digitalcorpora.org](http://digitalcorpora.org). The site includes a complete training scenario, including disk images, packet captures and exercises.

* The [UMass Trace Repository](http://traces.cs.umass.edu/index.php/Main/HomePage) provides network, storage, and other traces to the research community for analysis. The UMass Trace Repository is supported by grant #CNS-323597 from the National Science Foundation.

* UCI's [Network Data Repository](http://networkdata.ics.uci.edu/resources.php) provides data sets of a diverse set of networks. Some of the networks are related to computers, some aren't.

* [UT San Antonio Digital Corpora](http://digitalcorpora.org/corp/nps/files/filetypes1/)

* [long list of (mostly) open data sets](https://github.com/caesar0301/awesome-public-datasets)

Tools
-----

Other forensic tools include:

* [Sleuthkit](http://www.sleuthkit.org/)   

Sleuthkit can be installed on ubuntu based distributions using:

    sudo apt-get install sleuthkit

